---
---
@inproceedings{diddee-etal-2024-inmt-lite,
    title = "{INMT}-Lite: Accelerating Low-Resource Language Data Collection via Offline Interactive Neural Machine Translation",
    author = "Diddee, Harshita  and
      Shukla, Anurag  and
      Ganu, Tanuja  and
      Seshadri, Vivek  and
      Dandapat, Sandipan  and
      Choudhury, Monojit  and
      Bali, Kalika",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.797",
    pages = "9097--9109",
    selected = {true},
    abstract = "A steady increase in the performance of Massively Multilingual Models (MMLMs) has contributed to their rapidly increasing use in data collection pipelines. Interactive Neural Machine Translation (INMT) systems are one class of tools that can utilize MMLMs to promote such data collection in several under-resourced languages. However, these tools are often not adapted to the deployment constraints that native language speakers operate in, as bloated, online inference-oriented MMLMs trained for data-rich languages, drive them. INMT-Lite addresses these challenges through its support of (1) three different modes of Internet-independent deployment and (2) a suite of four assistive interfaces suitable for (3) data-sparse languages. We perform an extensive user study for INMT-Lite with an under-resourced language community, Gondi, to find that INMT-Lite improves the data generation experience of community members along multiple axes, such as cognitive load, task productivity, and interface interaction time and effort, without compromising on the quality of the generated translations.INMT-Lite{'}s code is open-sourced to further research in this domain.",
}


@inproceedings{Hada2024AkalBY,
  title={(Best Paper Award): Akal Badi ya Bias: An Exploratory Study of Gender Bias in Hindi Language Technology},
  author={Rishav Hada and Safiya Husain and Varun Gumma and Harshita Diddee and Aditya Yadavalli and Agrima Seth and Nidhi Kulkarni and Ujwal Gadiraju and Aditya Vashistha and Vivek Seshadri and Kalika Bali},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:269741028}, 
booktitle = "FAccT '23: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",
publisher= "Association For Computing Machinery"

}

@inproceedings{ahuja-etal-2023-mega,
    title = "{MEGA}: Multilingual Evaluation of Generative {AI}",
    author = "Ahuja, Kabir  and
      Diddee, Harshita  and
      Hada, Rishav  and
      Ochieng, Millicent  and
      Ramesh, Krithika  and
      Jain, Prachi  and
      Nambi, Akshay  and
      Ganu, Tanuja  and
      Segal, Sameer  and
      Ahmed, Mohamed  and
      Bali, Kalika  and
      Sitaram, Sunayana",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.258",
    doi = "10.18653/v1/2023.emnlp-main.258",
    pages = "4232--4267",
    abstract = "Generative AI models have shown impressive performance on many Natural Language Processing tasks such as language understanding, reasoning, and language generation. An important question being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative LLMs have been restricted to English and it is unclear how capable these models are at understanding and generating text in other languages. We present the first comprehensive benchmarking of generative LLMs - MEGA, which evaluates models on standard NLP benchmarks, covering 16 NLP datasets across 70 typologically diverse languages. We compare the performance of generative LLMs including Chat-GPT and GPT-4 to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages. We create a framework for evaluating generative LLMs in the multilingual setting and provide directions for future progress in the field.",
    pdf = "https://aclanthology.org/2023.emnlp-main.258",
    code = "https://github.com/microsoft/Multilingual-Evaluation-of-Generative-AI-MEGA",
    selected = {true}
}

@inproceedings{hada-etal-2023-fifty,
    title = "{``}Fifty Shades of Bias{''}: Normative Ratings of Gender Bias in {GPT} Generated {E}nglish Text",
    author = "Hada*, Rishav  and
      Seth*, Agrima  and
      Diddee, Harshita  and
      Bali, Kalika",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.115",
    doi = "10.18653/v1/2023.emnlp-main.115",
    pages = "1862--1876",
    abstract = "Language serves as a powerful tool for the manifestation of societal belief systems. In doing so, it also perpetuates the prevalent biases in our society. Gender bias is one of the most pervasive biases in our society and is seen in online and offline discourses. With LLMs increasingly gaining human-like fluency in text generation, gaining a nuanced understanding of the biases these systems can generate is imperative. Prior work often treats gender bias as a binary classification task. However, acknowledging that bias must be perceived at a relative scale; we investigate the generation and consequent receptivity of manual annotators to bias of varying degrees. Specifically, we create the first dataset of GPT-generated English text with normative ratings of gender bias. Ratings were obtained using Best{--}Worst Scaling {--} an efficient comparative annotation framework. Next, we systematically analyze the variation of themes of gender biases in the observed ranking and show that identity-attack is most closely related to gender bias. Finally, we show the performance of existing automated models trained on related concepts on our dataset.",
    pdf = "https://aclanthology.org/2023.emnlp-main.115"
}

@article{hada2023large,
  title={Are large language model-based evaluators the solution to scaling up multilingual evaluation?},
  author={Hada, Rishav and Gumma, Varun and de Wynter, Adrian and Diddee, Harshita and Ahmed, Mohamed and Choudhury, Monojit and Bali, Kalika and Sitaram, Sunayana},
  journal="Association for Computational Linguistics",
  year={2023},
  pdf = "https://aclanthology.org/2024.findings-eacl.71.pdf"
}

@article{naidu2021towards,
  title={Towards Quantifying the Carbon Emissions of Differentially Private Machine Learning},
  author = {Naidu, Rakshit and Diddee, Harshita and Mulay, Ajinkya and Vardhan, Aleti and Ramesh, Krithika and Zamzam, Ahmed},
  year = {2021},
  journal={Socially Responsible Machine Learning Workshop at ICML 2021}, 
  abstract = {In recent years, machine learning techniques utilizing large scale datasets have achieved remarkable performance. Differential privacy, by means of adding noise, provides strong privacy guarantees for such learning algorithms. The cost of differential privacy is often a reduced model accuracy and a lowered convergence speed. This paper investigates the impact of differential privacy on learning algorithms in terms of their carbon footprint due to either longer run-times or failed experiments. Through extensive experiments, further guidance is provided on choosing the noise levels which can strike a balance between desired privacy levels and reduced carbon emissions},
  pdf = {https://arxiv.org/pdf/2107.06946.pdf}, 
  code = {https://github.com/harshitadd/DP-Carbon-Footprint}
}

@article{10.1145/3571732,
author = {Madan, Chetan and Diddee, Harshita and Kumar, Deepika and Mittal, Mamta},
title = {CodeFed: Federated Speech Recognition for Low-Resource Code-Switching Detection},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3571732},
doi = {10.1145/3571732},
abstract = {One common constraint in the practical application of speech recognition is Code Switching. The issue of code-switched languages is especially aggravated in the context of Indian languages - since most massively multilingual models are trained on corpora that are not representative of the diverse set of Indian languages. An associated constraint with such systems is the privacy-intrusive nature of the applications that aim to collate such representative data. To collectively mitigate both problems, this works presents CodeFed: A federated learning-based code-switching detection model that can be deployed to collaboratively trained by leveraging private data from multiple users, without compromising their privacy. Using a representative low-resource Indic dataset, we demonstrate the superior performance of a collaboratively trained global model that is trained using federated learning on three low-resource Indic languages - Gujarati, Tamil and Telugu and draw a comparison of the model with respect to most current work in the field. Finally, to evaluate the practical realizability of the proposed system, CodeFed also discusses the system overview of the label generation architecture which may accompany CodeFed’s possible real-time deployment.},
note = {Just Accepted},
journal = {ACM Transactions Asian Low-Resource Language Information Processing (TALLIP)}, 
month = {08},
keywords = {Mobile Computing, Low Resource Indian Languages, Federated Learning, Code-Switching, Speech Processing}
}

@article{diddee2022too,
  title={Too Brittle To Touch: Comparing the Stability of Quantization and Distillation Towards Developing Lightweight Low-Resource MT Models},
  author={Diddee, Harshita and Dandapat, Sandipan and Choudhury, Monojit and Ganu, Tanuja and Bali, Kalika},
  abstract = {Leveraging shared learning through Massively Multilingual Models, state-of-the-art machine translation models are often able to adapt to the paucity of data for low-resource languages. However, this performance comes at the cost of significantly bloated models which are not practically deployable. Knowledge Distillation is one popular technique to develop competitive, lightweight models: In this work, we first evaluate its use to compress MT models focusing on languages with extremely limited training data. Through our analysis across 8 languages, we find that the variance in the performance of the distilled models due to their dependence on priors including the amount of synthetic data used for distillation, the student architecture, training hyperparameters and confidence of the teacher models, makes distillation a brittle compression mechanism. To mitigate this, we explore the use of post-training quantization for the compression of these models. Here, we find that while distillation provides gains across some low-resource languages, quantization provides more consistent performance trends for the entire range of languages, especially the lowest-resource languages in our target set.},
  journal={Conference On Machine Translation 2022}, 
  month = {10},
  year={2022}, 
  pdf = {https://aclanthology.org/2022.wmt-1.80/},
  selected={true}, 
  code = {https://github.com/microsoft/Lightweight-Low-Resource-NMT}
}

@article{ramesh2021samanantar,
    author = {Ramesh, Gowtham and Doddapaneni, Sumanth and Bheemaraj, Aravinth and Jobanputra, Mayank and AK, Raghavan and Sharma, Ajitesh and Sahoo, Sujit and Diddee, Harshita and J, Mahalakshmi and Kakwani, Divyanshu and Kumar, Navneet and Pradeep, Aswin and Nagaraj, Srihari and Deepak, Kumar and Raghavan, Vivek and Kunchukuttan, Anoop and Kumar, Pratyush and Khapra, Mitesh Shantadevi},
    title = "{Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages}",
    journal = {Transactions of the Association for Computational Linguistics},
    abstract = {We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4× increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages. Further, we extract 83.4 million sentence pairs between all 55 Indic language pairs from the English-centric parallel corpus using English as the pivot language. We trained multilingual NMT models spanning all these languages on Samanantar which outperform existing models and baselines on publicly available benchmarks, such as FLORES, establishing the utility of Samanantar. Our data and models are available publicly at Samanantar and we hope they will help advance research in NMT and multilingual NLP for Indic languages.},
    volume = {10},
    pages = {145-162},
    year = {2022},
    month = {02},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00452},
    pdf = {https://aclanthology.org/2022.tacl-1.9/}, 
    code = {https://github.com/harshitadd/indicOCR}, 
}

@inproceedings{10.1145/3530190.3534792,
author = {Diddee, Harshita and Bali, Kalika and Choudhury, Monojit and Mukhija, Namrata},
title = {The Six Conundrums of Building and Deploying Language Technologies for Social Good},
year = {2022},
month = {06},
isbn = {9781450393478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530190.3534792},
doi = {10.1145/3530190.3534792},
abstract = {Deployment of speech and language technology for social good (LT4SG), especially those targeted at the welfare of marginalized communities and speakers of low-resource and under-served languages, has been a prominent theme of research within NLP, Speech and the AI communities. Many researchers, especially those working in core NLP/Speech domains, rely on a combination of individual expertise, experiences or ad hoc surveys for prioritizing between language technologies that provide social good to the end-users. This has been criticized by several scholars who argue that it is critical to include the target community during the LT’s design and development process. However, prioritization of communities, languages, technologies and design approaches presents a very large set of complex challenges to the technologists, for which there are no simple or off-the-shelf solutions. In this position paper, we distill our experiential insights into six fundamental conundrums that technologists face and must resolve while deciding which LT technology to build for which community, and by using what approach. We discuss that at the root of these conundrums lie certain fundamental ethical problems of a digital-divide that can be overcome only by resolving deeper ethical dilemmas of distributive justice. We urge the community to reflect on these conundrums and leverage shared experiential insights to reconcile the intent of broadly, any Technology for Social Good, with the ground realities of its deployment.},
booktitle = {ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies (COMPASS)},
pages = {12–19},
pdf = {https://dl.acm.org/doi/10.1145/3530190.3534792},
numpages = {8},
keywords = {socio-technical deployment, language technology, community-centric development},
location = {Seattle, WA, USA},
series = {COMPASS 2022}
}

@inproceedings{chauhan-diddee-2020-psuedoprop,
    title = "{P}suedo{P}rop at {S}em{E}val-2020 Task 11: Propaganda Span Detection Using {BERT}-{CRF} and Ensemble Sentence Level Classifier",
    author = "Chauhan, Aniruddha  and
      Diddee, Harshita",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    pdf = "https://aclanthology.org/2020.semeval-1.233",
    doi = "10.18653/v1/2020.semeval-1.233",
    pages = "1779--1785",
    abstract = "This paper explains our teams{'} submission to the Shared Task of Fine-Grained Propaganda Detection in which we propose a sequential BERT-CRF based Span Identification model where the fine-grained detection is carried out only on the articles that are flagged as containing propaganda by an ensemble SLC model. We propose this setup bearing in mind the practicality of this approach in identifying propaganda spans in the exponentially increasing content base where the fine-tuned analysis of the entire data repository may not be the optimal choice due to its massive computational resource requirements. We present our analysis on different voting ensembles for the SLC model. Our system ranks 14th on the test set and 22nd on the development set and with an F1 score of 0.41 and 0.39 respectively.",
    code = {https://github.com/harshitadd/SemEval-Task-11}
}


@inproceedings{crosspriv,
author = {Diddee, Harshita and Kansra, Bhrigu},
title = {CrossPriv: User Privacy Preservation Model for Cross-Silo Federated Software},
year = {2020},
isbn = {978-1-4503-6768-4/20/09},
publisher = {IEEE Press},
pdf = {https://ieeexplore.ieee.org/document/9286125},
doi = {10.1145/3324884.3418911},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
numpages = {3},
abstract = {The design and implementation of artificial intelligence driven software that keeps user data private is a complex yet necessary requirement in the current times. Developers must consider several ethical and legal challenges while developing services which relay massive amount of private information over a network grid which is susceptible to attack from malicious agents. In most cases, organizations adopt a traditional model training approach where publicly available data, or data specifically collated for the task is used to train the model. Specifically in the healthcare section, the operation of deep learning algorithms on limited local data may introduce a significant bias to the system and the accuracy of the model may not be representative due to lack of richly covariate training data. In this paper, we propose CrossPriv, a user privacy preservation model for cross-silo Federated Learning systems to dictate some preliminary norms of SaaS based collaborative software. We discuss the client and server side characteristics of the software deployed on each side. Further, We demonstrate the efficacy of the proposed model by training a convolution neural network on distributed data of two different silos to detect pneumonia using X-Rays whilst not sharing any raw data between the silos.},
keywords = {data privacy, trust, collaborative training, distributed software},
location = {Virtual Event, Australia},
series = {ASE 2020}, 
code = {https://github.com/harshitadd/CrossPriv}
}

